from gensim import corpora, models, similarities  
import logging  
from collections import defaultdict    
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

#文档  
documents = ["Human machine interface for lab abc computer applications",  
"A survey of user opinion of computer system response time",   
"The EPS user interface management system",   
"System and human system engineering testing of EPS",  
"Relation of user perceived response time to error measurement",  
"The generation of random binary unordered trees",    
"The intersection graph of paths in trees",    
"Graph minors IV Widths of trees and well quasi ordering",    
"Graph minors A survey"]
#1.分词，去除停用词  
stoplist=set('for a of the and to in'.split())  
texts=[[word for word in document.lower().split() if word not in stoplist] for document in documents]#遍历文档并分词

print(texts)
#2.计算词频  
frequency = defaultdict(int) #构建一个字典对象  
#遍历分词后的结果集，计算每个词出现的频率  
for text in texts:  
    for token in text:  
        frequency[token]+=1  
#选择频率大于1的词  
texts=[[token for token in text if frequency[token]>1] for text in texts]

print(texts)
#3.创建字典（单词与编号之间的映射）  
dictionary=corpora.Dictionary(texts)  
#print(dictionary)  
#Dictionary(12 unique tokens: ['time', 'computer', 'graph', 'minors', 'trees']...)  
#打印字典，key为单词，value为单词的编号  
print(dictionary.token2id)  
#{'human': 0, 'interface': 1, 'computer': 2, 'survey': 3, 'user': 4, 'system': 5, 'response': 6, 'time': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}

new_doc = "Human computer interaction"
new_vec = dictionary.doc2bow(new_doc.lower().split())
print(new_vec)
corpus = [dictionary.doc2bow(text) for text in texts]
print(corpus)
#6.初始化模型  
# 初始化一个tfidf模型,可以用它来转换向量（词袋整数计数）表示方法为新的表示方法（Tfidf 实数权重）  
tfidf = models.TfidfModel(corpus)  
#测试  
test_doc_bow = [(0, 1), (1, 1)]  
print(tfidf[test_doc_bow])  
#[(0, 0.7071067811865476), (1, 0.7071067811865476)]

#6.初始化模型  
# 初始化一个tfidf模型,可以用它来转换向量（词袋整数计数）表示方法为新的表示方法（Tfidf 实数权重）  
tfidf = models.TfidfModel(corpus)  
#测试  
test_doc_bow = [(0, 12), (1, 1)]  
print(tfidf[test_doc_bow])  
#[(0, 0.7071067811865476), (1, 0.7071067811865476)]

corpus_tfidf = tfidf[corpus]  
for doc in corpus_tfidf:  
    print(doc)
    
#7.创建索引  
index = similarities.MatrixSimilarity(corpus_tfidf)
#8.相似度计算  
new_vec_tfidf=tfidf[new_vec]#将要比较文档转换为tfidf表示方法  
print(new_vec_tfidf)  
#[(0, 0.7071067811865476), (2, 0.7071067811865476)]  

#计算要比较的文档与语料库中每篇文档的相似度  
sims = index[new_vec_tfidf]  
print(sims)  
#[ 0.81649655  0.31412902  0.          0.34777319  0.          0.          0.  
#  0.          0.        ]
